#!/bin/bash
#
# use like:
#   sbatch -J jobname run.sh
#
# Don't restart if failing:
#SBATCH --no-requeue
# Whole node to our selves:
#SBATCH --exclusive
# Number of processes per node:
#SBATCH --ntasks-per-node=24
# Total number of processes:
#SBATCH -n 384
# Number of nodes:
#SBATCH -N 16
# Time required: Days-hours:mins:secs
#SBATCH --time 3-00:00:00
# Load intel mpi that solfec-mpi is compiled against:
module load gcc
# print input config:
echo "sbatch_script: jobid = $SLURM_JOB_ID"
echo "sbatch_script: jobname = $SLURM_JOB_NAME"
echo "sbatch_script: nodes = $SLURM_NODELIST"
echo "sbatch_script: n_processes = $SLURM_NPROCS"
echo "sbatch_script: cwd = `pwd`"
echo "sbatch_script: started mpirun `date`:"
# command:
mpirun solfec-mpi input-file.py
echo "sbatch_script: ended mpirun: `date`"
# move the logfile:
set -x
file_ext='_run_dyn'
mv slurm-$SLURM_JOB_ID.out $SLURM_JOB_NAME$file_ext.out
